# ParameterOptimization

## ABOUT SVM
This article was published as a part of the Data Science Blogathon
SVM is a powerful supervised algorithm that works best on smaller datasets but on complex ones. Support Vector Machine, abbreviated as SVM can be used for both regression and classification tasks, but generally, they work best in classification problems. They were very famous around the time they were created, during the 1990s, and keep on being the go-to method for a high-performing algorithm with a little tuning.

Support Vector Machine (SVM) is a relatively simple Supervised Machine Learning Algorithm used for classification and/or regression. It is more preferred for classification but is sometimes very useful for regression as well. Basically, SVM finds a hyper-plane that creates a boundary between the types of data. In 2-dimensional space, this hyper-plane is nothing but a line. In SVM, we plot each data item in the dataset in an N-dimensional space, where N is the number of features/attributes in the data. Next, find the optimal hyperplane to separate the data. So by this, you must have understood that inherently, SVM can only perform binary classification (i.e., choose between two classes). However, there are various techniques to use for multi-class problems.

## Accuracy Table
![image](https://user-images.githubusercontent.com/111976583/233167003-3c483bd7-3803-4ebc-928c-8a1492b9559c.png)

## Convergence Graph
![image](https://user-images.githubusercontent.com/111976583/233166277-db51b8ce-6a09-4e01-8ff4-a82d29109be9.png)

## Discussion 
From Above Graph we come to know that with increase in iteration Cross Validation Score Converges to Training Score

### By Sourav Choubey
### 102016075
### 3CS11
